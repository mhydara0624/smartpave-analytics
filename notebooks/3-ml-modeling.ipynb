{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SmartPave Analytics: Machine Learning Modeling\n",
        "\n",
        "## Overview\n",
        "This notebook trains machine learning models to predict pavement degradation, estimate repair costs, and prioritize maintenance activities.\n",
        "\n",
        "## Objectives\n",
        "- Train degradation prediction model\n",
        "- Build cost estimation model\n",
        "- Develop priority scoring algorithm\n",
        "- Evaluate model performance\n",
        "- Create ensemble predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries for machine learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Connect to Snowflake\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE DOT_workshop_test\").collect()\n",
        "session.sql(\"USE SCHEMA smartpave_analytics\").collect()\n",
        "\n",
        "print(\"ML libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed features from Snowflake\n",
        "print(\"Loading processed features for ML modeling...\")\n",
        "\n",
        "# Load the features table created in notebook 2\n",
        "features_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.pavement_features\").to_pandas()\n",
        "print(f\"Loaded {len(features_df):,} feature records\")\n",
        "\n",
        "# Load additional data for cost prediction\n",
        "maintenance_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.maintenance_records\").to_pandas()\n",
        "maintenance_df['date'] = pd.to_datetime(maintenance_df['date'])\n",
        "\n",
        "print(f\"Loaded {len(maintenance_df):,} maintenance records\")\n",
        "\n",
        "# Display feature information\n",
        "print(f\"\\nFeature columns available: {len(features_df.columns)}\")\n",
        "print(f\"Features: {list(features_df.columns)}\")\n",
        "print(f\"\\nSample of features data:\")\n",
        "print(features_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 1: Pavement Condition Prediction\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL 1: PAVEMENT CONDITION PREDICTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Prepare features for condition prediction\n",
        "feature_columns = ['days_since_last_repair', 'season', 'month', 'year', 'condition_trend',\n",
        "                  'traffic_stress', 'traffic_volume', 'weather_damage', 'precipitation_30d_avg',\n",
        "                  'freeze_thaw_30d_sum', 'total_maintenance_cost', 'repair_count', \n",
        "                  'avg_repair_cost', 'avg_effectiveness', 'days_since_last_maintenance',\n",
        "                  'lanes', 'segment_length_miles', 'distance_from_center']\n",
        "\n",
        "# Handle categorical variables\n",
        "le_road_type = LabelEncoder()\n",
        "le_region = LabelEncoder()\n",
        "features_df['road_type_encoded'] = le_road_type.fit_transform(features_df['road_type'])\n",
        "features_df['region_encoded'] = le_region.fit_transform(features_df['region'])\n",
        "\n",
        "# Add encoded categorical features\n",
        "feature_columns.extend(['road_type_encoded', 'region_encoded'])\n",
        "\n",
        "# Prepare data\n",
        "X = features_df[feature_columns].fillna(0)\n",
        "y = features_df['condition_score']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Split data (time-aware split)\n",
        "features_df_sorted = features_df.sort_values('date')\n",
        "split_date = features_df_sorted['date'].quantile(0.8)\n",
        "train_mask = features_df_sorted['date'] < split_date\n",
        "\n",
        "X_train = X[train_mask]\n",
        "X_test = X[~train_mask]\n",
        "y_train = y[train_mask]\n",
        "y_test = y[~train_mask]\n",
        "\n",
        "print(f\"Training set: {len(X_train):,} samples\")\n",
        "print(f\"Test set: {len(X_test):,} samples\")\n",
        "\n",
        "# Train multiple models\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    \n",
        "    # Metrics\n",
        "    train_r2 = r2_score(y_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_test, y_pred_test)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    \n",
        "    results[name] = {\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'model': model\n",
        "    }\n",
        "    \n",
        "    print(f\"  Train RÂ²: {train_r2:.3f}, Test RÂ²: {test_r2:.3f}\")\n",
        "    print(f\"  Train RMSE: {train_rmse:.3f}, Test RMSE: {test_rmse:.3f}\")\n",
        "\n",
        "# Find best model\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['test_r2'])\n",
        "best_model = results[best_model_name]['model']\n",
        "print(f\"\\nðŸ† Best model: {best_model_name} (RÂ² = {results[best_model_name]['test_r2']:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 2: Maintenance Cost Prediction\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL 2: MAINTENANCE COST PREDICTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Prepare cost prediction data\n",
        "cost_features = features_df.merge(maintenance_df[['segment_id', 'date', 'cost', 'repair_type']], \n",
        "                                 on=['segment_id', 'date'], how='inner')\n",
        "\n",
        "# Encode repair type\n",
        "le_repair_type = LabelEncoder()\n",
        "cost_features['repair_type_encoded'] = le_repair_type.fit_transform(cost_features['repair_type'])\n",
        "\n",
        "# Features for cost prediction\n",
        "cost_feature_columns = ['condition_score', 'days_since_last_repair', 'traffic_stress', \n",
        "                       'weather_damage', 'lanes', 'segment_length_miles', 'repair_type_encoded']\n",
        "\n",
        "X_cost = cost_features[cost_feature_columns].fillna(0)\n",
        "y_cost = cost_features['cost']\n",
        "\n",
        "print(f\"Cost prediction features: {X_cost.shape}\")\n",
        "print(f\"Cost targets: {y_cost.shape}\")\n",
        "\n",
        "# Split cost data\n",
        "X_cost_train, X_cost_test, y_cost_train, y_cost_test = train_test_split(\n",
        "    X_cost, y_cost, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train cost prediction models\n",
        "cost_models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)\n",
        "}\n",
        "\n",
        "cost_results = {}\n",
        "for name, model in cost_models.items():\n",
        "    print(f\"\\nTraining {name} for cost prediction...\")\n",
        "    model.fit(X_cost_train, y_cost_train)\n",
        "    \n",
        "    y_cost_pred = model.predict(X_cost_test)\n",
        "    r2 = r2_score(y_cost_test, y_cost_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_cost_test, y_cost_pred))\n",
        "    \n",
        "    cost_results[name] = {'r2': r2, 'rmse': rmse, 'model': model}\n",
        "    print(f\"  RÂ²: {r2:.3f}, RMSE: ${rmse:,.0f}\")\n",
        "\n",
        "# Find best cost model\n",
        "best_cost_model_name = max(cost_results.keys(), key=lambda x: cost_results[x]['r2'])\n",
        "print(f\"\\nðŸ† Best cost model: {best_cost_model_name} (RÂ² = {cost_results[best_cost_model_name]['r2']:.3f})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
