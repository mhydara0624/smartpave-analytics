{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SmartPave Analytics: Machine Learning Modeling\n",
        "\n",
        "## Overview\n",
        "This notebook trains machine learning models to predict pavement degradation, estimate repair costs, and prioritize maintenance activities.\n",
        "\n",
        "## Objectives\n",
        "- Train degradation prediction model\n",
        "- Build cost estimation model\n",
        "- Develop priority scoring algorithm\n",
        "- Evaluate model performance\n",
        "- Create ensemble predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries for machine learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Connect to Snowflake\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE DOT_workshop_test\").collect()\n",
        "session.sql(\"USE SCHEMA smartpave_analytics\").collect()\n",
        "\n",
        "print(\"ML libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed features from Snowflake\n",
        "print(\"Loading processed features for ML modeling...\")\n",
        "\n",
        "# Load the features table created in notebook 2\n",
        "features_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.pavement_features\").to_pandas()\n",
        "print(f\"Loaded {len(features_df):,} feature records\")\n",
        "\n",
        "# Load additional data for cost prediction\n",
        "maintenance_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.maintenance_records\").to_pandas()\n",
        "if 'DATE' in maintenance_df.columns:\n",
        "    maintenance_df['DATE'] = pd.to_datetime(maintenance_df['DATE'])\n",
        "\n",
        "print(f\"Loaded {len(maintenance_df):,} maintenance records\")\n",
        "\n",
        "# Display feature information\n",
        "print(f\"\\nFeature columns available: {len(features_df.columns)}\")\n",
        "print(f\"Sample features: {list(features_df.columns)[:10]}...\")\n",
        "\n",
        "# Detect key columns dynamically\n",
        "date_col = None\n",
        "condition_score_col = None\n",
        "segment_id_col = None\n",
        "\n",
        "for col in features_df.columns:\n",
        "    if col.upper() == 'DATE':\n",
        "        date_col = col\n",
        "    elif col.upper() == 'CONDITION_SCORE':\n",
        "        condition_score_col = col\n",
        "    elif col.upper() == 'SEGMENT_ID':\n",
        "        segment_id_col = col\n",
        "\n",
        "print(f\"\\nDetected key columns:\")\n",
        "print(f\"  Date: {date_col}\")\n",
        "print(f\"  Condition Score: {condition_score_col}\")\n",
        "print(f\"  Segment ID: {segment_id_col}\")\n",
        "\n",
        "# Show sample data\n",
        "print(f\"\\nSample of features data:\")\n",
        "print(features_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 1: Pavement Condition Prediction\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL 1: PAVEMENT CONDITION PREDICTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# WORKSHOP OPTIMIZATION: Use sample for faster training\n",
        "print(\"ðŸ”§ WORKSHOP MODE: Using sample for faster ML training...\")\n",
        "sample_size = min(50000, len(features_df))  # Max 50K records for ML\n",
        "features_sample = features_df.sample(n=sample_size, random_state=42).copy()\n",
        "print(f\"Using sample: {len(features_sample):,} records for ML training\")\n",
        "\n",
        "# Select features that actually exist in our data\n",
        "available_features = []\n",
        "feature_candidates = [\n",
        "    'month', 'quarter', 'year', 'season', 'days_since_last_inspection', 'degradation_rate',\n",
        "    'traffic_stress', 'heavy_truck_impact', 'traffic_category', 'TRAFFIC_VOLUME',\n",
        "    'freeze_thaw_damage', 'precipitation_damage', 'temperature_stress', 'total_weather_damage',\n",
        "    'days_since_last_maintenance', 'maintenance_frequency', 'avg_maintenance_cost', 'total_maintenance_cost',\n",
        "    'is_highway', 'is_arterial', 'is_local', 'ROAD_LATITUDE', 'ROAD_LONGITUDE',\n",
        "    'condition_avg_30d', 'condition_avg_90d', 'condition_std_30d', 'condition_std_90d',\n",
        "    'condition_lag_1m', 'condition_lag_3m', 'condition_lag_6m', 'condition_trend_3m',\n",
        "    'traffic_weather_interaction', 'risk_score'\n",
        "]\n",
        "\n",
        "for feature in feature_candidates:\n",
        "    if feature in features_sample.columns:\n",
        "        available_features.append(feature)\n",
        "\n",
        "print(f\"Available features for ML: {len(available_features)}\")\n",
        "print(f\"Features: {available_features}\")\n",
        "\n",
        "# Prepare data - handle categorical variables\n",
        "print(\"Preparing features for ML...\")\n",
        "\n",
        "# Encode categorical variables\n",
        "X_processed = features_sample[available_features].copy()\n",
        "\n",
        "# Handle season column (categorical)\n",
        "if 'season' in X_processed.columns:\n",
        "    le_season = LabelEncoder()\n",
        "    X_processed['season_encoded'] = le_season.fit_transform(X_processed['season'].fillna('Unknown'))\n",
        "    X_processed = X_processed.drop('season', axis=1)\n",
        "\n",
        "# Handle traffic_category column (categorical)\n",
        "if 'traffic_category' in X_processed.columns:\n",
        "    le_traffic = LabelEncoder()\n",
        "    X_processed['traffic_category_encoded'] = le_traffic.fit_transform(X_processed['traffic_category'].fillna('Unknown'))\n",
        "    X_processed = X_processed.drop('traffic_category', axis=1)\n",
        "\n",
        "# Fill remaining NaN values and ensure numeric types\n",
        "X = X_processed.fillna(0).astype(float)\n",
        "y = features_sample[condition_score_col]\n",
        "\n",
        "print(f\"Features after encoding: {X.shape}\")\n",
        "print(f\"Feature columns: {list(X.columns)}\")\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Split data (time-aware split if date available)\n",
        "if date_col:\n",
        "    features_sample_sorted = features_sample.sort_values(date_col)\n",
        "    split_date = features_sample_sorted[date_col].quantile(0.8)\n",
        "    train_mask = features_sample_sorted[date_col] < split_date\n",
        "    \n",
        "    X_train = X[train_mask]\n",
        "    X_test = X[~train_mask]\n",
        "    y_train = y[train_mask]\n",
        "    y_test = y[~train_mask]\n",
        "else:\n",
        "    # Random split if no date\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(X_train):,} samples\")\n",
        "print(f\"Test set: {len(X_test):,} samples\")\n",
        "\n",
        "# Train multiple models (workshop optimized - fewer estimators)\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=50, random_state=42),\n",
        "    'XGBoost': xgb.XGBRegressor(n_estimators=50, random_state=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(n_estimators=50, random_state=42, verbose=-1)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    \n",
        "    # Metrics\n",
        "    train_r2 = r2_score(y_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_test, y_pred_test)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    \n",
        "    results[name] = {\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'model': model,\n",
        "        'training_time': training_time\n",
        "    }\n",
        "    \n",
        "    print(f\"  Train RÂ²: {train_r2:.3f}, Test RÂ²: {test_r2:.3f}\")\n",
        "    print(f\"  Train RMSE: {train_rmse:.3f}, Test RMSE: {test_rmse:.3f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "# Find best model\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['test_r2'])\n",
        "best_model = results[best_model_name]['model']\n",
        "print(f\"\\nðŸ† Best model: {best_model_name} (RÂ² = {results[best_model_name]['test_r2']:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 2: Maintenance Cost Prediction\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL 2: MAINTENANCE COST PREDICTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Prepare cost prediction data\n",
        "print(\"Preparing cost prediction data...\")\n",
        "\n",
        "# Merge features with maintenance data\n",
        "if 'SEGMENT_ID' in maintenance_df.columns and 'DATE' in maintenance_df.columns:\n",
        "    # Check what columns are available in maintenance data\n",
        "    print(f\"Available maintenance columns: {list(maintenance_df.columns)}\")\n",
        "    \n",
        "    available_maintenance_cols = ['SEGMENT_ID', 'DATE']\n",
        "    cost_col = None\n",
        "    \n",
        "    # Find cost column (could be 'COST', 'cost', or similar)\n",
        "    for col in maintenance_df.columns:\n",
        "        if 'COST' in col.upper():\n",
        "            cost_col = col\n",
        "            available_maintenance_cols.append(col)\n",
        "            break\n",
        "    \n",
        "    if 'REPAIR_TYPE' in maintenance_df.columns:\n",
        "        available_maintenance_cols.append('REPAIR_TYPE')\n",
        "    \n",
        "    print(f\"Using maintenance columns: {available_maintenance_cols}\")\n",
        "    print(f\"Cost column found: {cost_col}\")\n",
        "    \n",
        "    if cost_col:\n",
        "        cost_features = features_sample.merge(\n",
        "            maintenance_df[available_maintenance_cols], \n",
        "            left_on=[segment_id_col, date_col], \n",
        "            right_on=['SEGMENT_ID', 'DATE'], \n",
        "            how='inner'\n",
        "        )\n",
        "        print(f\"Cost prediction dataset: {len(cost_features):,} records\")\n",
        "        \n",
        "        # Encode repair type if available\n",
        "        if 'REPAIR_TYPE' in cost_features.columns:\n",
        "            le_repair_type = LabelEncoder()\n",
        "            cost_features['repair_type_encoded'] = le_repair_type.fit_transform(cost_features['REPAIR_TYPE'].fillna('Unknown'))\n",
        "        else:\n",
        "            print(\"âš ï¸ REPAIR_TYPE not available - using dummy repair type\")\n",
        "            cost_features['repair_type_encoded'] = 0\n",
        "    else:\n",
        "        print(\"âš ï¸ No cost column found in maintenance data\")\n",
        "        cost_features = None\n",
        "    \n",
        "    if cost_features is not None:\n",
        "        # Select available features for cost prediction\n",
        "        cost_feature_candidates = [\n",
        "            condition_score_col, 'traffic_stress', 'heavy_truck_impact', 'total_weather_damage',\n",
        "            'days_since_last_maintenance', 'maintenance_frequency', 'avg_maintenance_cost',\n",
        "            'is_highway', 'is_arterial', 'is_local', 'repair_type_encoded'\n",
        "        ]\n",
        "        \n",
        "        cost_available_features = [f for f in cost_feature_candidates if f in cost_features.columns]\n",
        "        \n",
        "        X_cost = cost_features[cost_available_features].fillna(0)\n",
        "        y_cost = cost_features[cost_col]  # Use the detected cost column\n",
        "        \n",
        "        print(f\"Cost prediction features: {X_cost.shape}\")\n",
        "        print(f\"Cost targets: {y_cost.shape}\")\n",
        "        print(f\"Features used: {cost_available_features}\")\n",
        "        \n",
        "        # Split cost data\n",
        "        X_cost_train, X_cost_test, y_cost_train, y_cost_test = train_test_split(\n",
        "            X_cost, y_cost, test_size=0.2, random_state=42)\n",
        "        \n",
        "        # Train cost prediction models (workshop optimized)\n",
        "        cost_models = {\n",
        "            'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1),\n",
        "            'XGBoost': xgb.XGBRegressor(n_estimators=50, random_state=42),\n",
        "            'LightGBM': lgb.LGBMRegressor(n_estimators=50, random_state=42, verbose=-1)\n",
        "        }\n",
        "        \n",
        "        cost_results = {}\n",
        "        for name, model in cost_models.items():\n",
        "            print(f\"\\nTraining {name} for cost prediction...\")\n",
        "            start_time = time.time()\n",
        "            model.fit(X_cost_train, y_cost_train)\n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            y_cost_pred = model.predict(X_cost_test)\n",
        "            r2 = r2_score(y_cost_test, y_cost_pred)\n",
        "            rmse = np.sqrt(mean_squared_error(y_cost_test, y_cost_pred))\n",
        "            \n",
        "            cost_results[name] = {'r2': r2, 'rmse': rmse, 'model': model, 'training_time': training_time}\n",
        "            print(f\"  RÂ²: {r2:.3f}, RMSE: ${rmse:,.0f}\")\n",
        "            print(f\"  Training time: {training_time:.1f}s\")\n",
        "        \n",
        "        # Find best cost model\n",
        "        best_cost_model_name = max(cost_results.keys(), key=lambda x: cost_results[x]['r2'])\n",
        "        print(f\"\\nðŸ† Best cost model: {best_cost_model_name} (RÂ² = {cost_results[best_cost_model_name]['r2']:.3f})\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Cannot proceed with cost prediction - no cost data available\")\n",
        "        cost_results = {}\n",
        "    \n",
        "else:\n",
        "    print(\"âš ï¸ Maintenance data not available or missing required columns\")\n",
        "    print(\"Skipping cost prediction model...\")\n",
        "    cost_results = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Performance Summary\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"ðŸ† CONDITION PREDICTION MODELS:\")\n",
        "for name, result in results.items():\n",
        "    print(f\"  {name}:\")\n",
        "    print(f\"    Test RÂ²: {result['test_r2']:.3f}\")\n",
        "    print(f\"    Test RMSE: {result['test_rmse']:.3f}\")\n",
        "    print(f\"    Training time: {result['training_time']:.1f}s\")\n",
        "\n",
        "if 'cost_results' in locals() and cost_results:\n",
        "    print(\"\\nðŸ† COST PREDICTION MODELS:\")\n",
        "    for name, result in cost_results.items():\n",
        "        print(f\"  {name}:\")\n",
        "        print(f\"    Test RÂ²: {result['r2']:.3f}\")\n",
        "        print(f\"    Test RMSE: ${result['rmse']:,.0f}\")\n",
        "        print(f\"    Training time: {result['training_time']:.1f}s\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ Cost prediction models not available\")\n",
        "\n",
        "print(f\"\\nðŸ“Š WORKSHOP OPTIMIZATIONS:\")\n",
        "print(f\"  - Used sample data: {len(features_sample):,} records\")\n",
        "print(f\"  - Reduced estimators: 50 (vs 100)\")\n",
        "print(f\"  - Parallel processing: Enabled\")\n",
        "print(f\"  - Total features used: {len(available_features)}\")\n",
        "\n",
        "print(f\"\\nâœ… ML MODELING COMPLETE!\")\n",
        "print(f\"Best condition model: {best_model_name}\")\n",
        "if 'cost_results' in locals() and cost_results:\n",
        "    print(f\"Best cost model: {best_cost_model_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
