{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SmartPave Analytics: Data Exploration\n",
        "\n",
        "## Overview\n",
        "This notebook explores the pavement condition and maintenance data for 16,000 miles of roadway infrastructure.\n",
        "\n",
        "## Objectives\n",
        "- Load and examine the dataset structure\n",
        "- Understand data quality and completeness\n",
        "- Create initial visualizations\n",
        "- Identify patterns and trends\n",
        "- Prepare for feature engineering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure pandas display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set database context and load datasets from Snowflake tables\n",
        "print(\"Loading datasets from Snowflake...\")\n",
        "\n",
        "# Connect to Snowflake and set context\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE DOT_workshop_test\").collect()\n",
        "session.sql(\"USE SCHEMA smartpave_analytics\").collect()\n",
        "\n",
        "# Check if tables exist first\n",
        "print(\"Checking if tables exist...\")\n",
        "tables_check = session.sql(\"\"\"\n",
        "    SELECT table_name \n",
        "    FROM information_schema.tables \n",
        "    WHERE table_schema = 'SMARTPAVE_ANALYTICS'\n",
        "\"\"\").to_pandas()\n",
        "print(f\"Available tables: {list(tables_check['TABLE_NAME'])}\")\n",
        "\n",
        "# Check table schemas to see what columns actually exist\n",
        "print(\"\\nChecking table schemas...\")\n",
        "for table in ['road_network', 'pavement_condition', 'maintenance_records', 'traffic_data']:\n",
        "    try:\n",
        "        schema_info = session.sql(f\"\"\"\n",
        "            SELECT column_name, data_type \n",
        "            FROM information_schema.columns \n",
        "            WHERE table_schema = 'SMARTPAVE_ANALYTICS' \n",
        "            AND table_name = '{table.upper()}'\n",
        "            ORDER BY ordinal_position\n",
        "        \"\"\").to_pandas()\n",
        "        print(f\"\\n{table} table schema:\")\n",
        "        print(schema_info)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not get schema for {table}: {e}\")\n",
        "\n",
        "# Road network data\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Loading road network data...\")\n",
        "try:\n",
        "    roads_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.road_network\").to_pandas()\n",
        "    print(f\"✅ Road network: {len(roads_df):,} segments\")\n",
        "    print(f\"   Columns: {list(roads_df.columns)}\")\n",
        "    if len(roads_df) > 0:\n",
        "        print(f\"   Sample data:\\n{roads_df.head()}\")\n",
        "    else:\n",
        "        print(\"   ⚠️ No data in road_network table\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading road_network: {e}\")\n",
        "    roads_df = pd.DataFrame()\n",
        "\n",
        "# Pavement condition data\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Loading pavement condition data...\")\n",
        "try:\n",
        "    condition_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.pavement_condition\").to_pandas()\n",
        "    print(f\"✅ Pavement condition: {len(condition_df):,} records\")\n",
        "    print(f\"   Columns: {list(condition_df.columns)}\")\n",
        "    if len(condition_df) > 0:\n",
        "        print(f\"   Sample data:\\n{condition_df.head()}\")\n",
        "        # Check if date column exists and convert if it does (handle case sensitivity)\n",
        "        date_col = None\n",
        "        for col in condition_df.columns:\n",
        "            if col.upper() == 'DATE':\n",
        "                date_col = col\n",
        "                break\n",
        "        \n",
        "        if date_col:\n",
        "            condition_df['date'] = pd.to_datetime(condition_df[date_col])\n",
        "            print(f\"   ✅ Date column '{date_col}' converted to datetime\")\n",
        "        else:\n",
        "            print(\"   ⚠️ No 'DATE' column found\")\n",
        "            # Look for any date-like columns\n",
        "            date_like_cols = [col for col in condition_df.columns if any(word in col.lower() for word in ['date', 'time', 'year', 'month', 'day'])]\n",
        "            print(f\"   Date-like columns found: {date_like_cols}\")\n",
        "    else:\n",
        "        print(\"   ⚠️ No data in pavement_condition table\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading pavement_condition: {e}\")\n",
        "    condition_df = pd.DataFrame()\n",
        "\n",
        "# Maintenance records\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Loading maintenance records...\")\n",
        "try:\n",
        "    maintenance_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.maintenance_records\").to_pandas()\n",
        "    print(f\"✅ Maintenance records: {len(maintenance_df):,} records\")\n",
        "    print(f\"   Columns: {list(maintenance_df.columns)}\")\n",
        "    if len(maintenance_df) > 0:\n",
        "        print(f\"   Sample data:\\n{maintenance_df.head()}\")\n",
        "        # Check if date column exists and convert if it does (handle case sensitivity)\n",
        "        date_col = None\n",
        "        for col in maintenance_df.columns:\n",
        "            if col.upper() == 'DATE':\n",
        "                date_col = col\n",
        "                break\n",
        "        \n",
        "        if date_col:\n",
        "            maintenance_df['date'] = pd.to_datetime(maintenance_df[date_col])\n",
        "            print(f\"   ✅ Date column '{date_col}' converted to datetime\")\n",
        "        else:\n",
        "            print(\"   ⚠️ No 'DATE' column found\")\n",
        "            # Look for any date-like columns\n",
        "            date_like_cols = [col for col in maintenance_df.columns if any(word in col.lower() for word in ['date', 'time', 'year', 'month', 'day'])]\n",
        "            print(f\"   Date-like columns found: {date_like_cols}\")\n",
        "    else:\n",
        "        print(\"   ⚠️ No data in maintenance_records table\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading maintenance_records: {e}\")\n",
        "    maintenance_df = pd.DataFrame()\n",
        "\n",
        "# Traffic data\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Loading traffic data...\")\n",
        "try:\n",
        "    traffic_df = session.sql(\"SELECT * FROM DOT_workshop_test.smartpave_analytics.traffic_data\").to_pandas()\n",
        "    print(f\"✅ Traffic data: {len(traffic_df):,} records\")\n",
        "    print(f\"   Columns: {list(traffic_df.columns)}\")\n",
        "    if len(traffic_df) > 0:\n",
        "        print(f\"   Sample data:\\n{traffic_df.head()}\")\n",
        "    else:\n",
        "        print(\"   ⚠️ No data in traffic_data table\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading traffic_data: {e}\")\n",
        "    traffic_df = pd.DataFrame()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA LOADING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Road network: {len(roads_df):,} records\")\n",
        "print(f\"Pavement condition: {len(condition_df):,} records\") \n",
        "print(f\"Maintenance records: {len(maintenance_df):,} records\")\n",
        "print(f\"Traffic data: {len(traffic_df):,} records\")\n",
        "\n",
        "# Check for date columns specifically\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATE COLUMN ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "for name, df in [(\"Road Network\", roads_df), (\"Pavement Condition\", condition_df), \n",
        "                (\"Maintenance Records\", maintenance_df), (\"Traffic Data\", traffic_df)]:\n",
        "    if len(df) > 0:\n",
        "        date_cols = [col for col in df.columns if any(word in col.lower() for word in ['date', 'time', 'year', 'month', 'day'])]\n",
        "        print(f\"{name}: {date_cols if date_cols else 'No date columns found'}\")\n",
        "\n",
        "if len(condition_df) == 0:\n",
        "    print(\"\\n🚨 CRITICAL: No pavement condition data loaded!\")\n",
        "    print(\"   This will prevent ML modeling from working.\")\n",
        "    print(\"   Please check if data was loaded into the tables.\")\n",
        "elif not any(col.upper() == 'DATE' for col in condition_df.columns):\n",
        "    print(\"\\n🚨 CRITICAL: No date column in pavement condition data!\")\n",
        "    print(\"   This will severely impact ML modeling capabilities.\")\n",
        "    print(\"   Time-based features are essential for pavement analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset Overview and Basic Statistics\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Basic statistics\n",
        "print(f\"📊 Dataset Summary:\")\n",
        "print(f\"   • Road segments: {len(roads_df):,}\")\n",
        "print(f\"   • Pavement records: {len(condition_df):,}\")\n",
        "print(f\"   • Maintenance records: {len(maintenance_df):,}\")\n",
        "print(f\"   • Traffic records: {len(traffic_df):,}\")\n",
        "\n",
        "# Date ranges (only if date columns exist)\n",
        "print(f\"\\n📅 Date Ranges:\")\n",
        "if 'date' in condition_df.columns:\n",
        "    print(f\"   • Pavement data: {condition_df['date'].min().strftime('%Y-%m-%d')} to {condition_df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "else:\n",
        "    print(\"   • Pavement data: No date column available\")\n",
        "\n",
        "if 'date' in maintenance_df.columns:\n",
        "    print(f\"   • Maintenance data: {maintenance_df['date'].min().strftime('%Y-%m-%d')} to {maintenance_df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "else:\n",
        "    print(\"   • Maintenance data: No date column available\")\n",
        "\n",
        "# Road types distribution\n",
        "print(f\"\\n🛣️ Road Types:\")\n",
        "road_type_col = None\n",
        "for col in roads_df.columns:\n",
        "    if col.upper() == 'ROAD_TYPE':\n",
        "        road_type_col = col\n",
        "        break\n",
        "\n",
        "if road_type_col:\n",
        "    road_type_counts = roads_df[road_type_col].value_counts()\n",
        "    for road_type, count in road_type_counts.items():\n",
        "        print(f\"   • {road_type}: {count:,} segments ({count/len(roads_df)*100:.1f}%)\")\n",
        "else:\n",
        "    print(\"   • No road_type column found\")\n",
        "\n",
        "# Condition score statistics\n",
        "print(f\"\\n📈 Pavement Condition Statistics:\")\n",
        "condition_score_col = None\n",
        "for col in condition_df.columns:\n",
        "    if col.upper() == 'CONDITION_SCORE':\n",
        "        condition_score_col = col\n",
        "        break\n",
        "\n",
        "if condition_score_col:\n",
        "    print(f\"   • Average condition score: {condition_df[condition_score_col].mean():.1f}\")\n",
        "    print(f\"   • Median condition score: {condition_df[condition_score_col].median():.1f}\")\n",
        "    print(f\"   • Best condition: {condition_df[condition_score_col].max():.1f}\")\n",
        "    print(f\"   • Worst condition: {condition_df[condition_score_col].min():.1f}\")\n",
        "else:\n",
        "    print(\"   • No condition_score column found\")\n",
        "\n",
        "# Maintenance cost statistics\n",
        "print(f\"\\n💰 Maintenance Cost Statistics:\")\n",
        "cost_col = None\n",
        "for col in maintenance_df.columns:\n",
        "    if col.upper() == 'COST':\n",
        "        cost_col = col\n",
        "        break\n",
        "\n",
        "if cost_col:\n",
        "    print(f\"   • Total maintenance cost: ${maintenance_df[cost_col].sum():,.0f}\")\n",
        "    print(f\"   • Average repair cost: ${maintenance_df[cost_col].mean():,.0f}\")\n",
        "    print(f\"   • Most expensive repair: ${maintenance_df[cost_col].max():,.0f}\")\n",
        "    print(f\"   • Total repairs: {len(maintenance_df):,}\")\n",
        "else:\n",
        "    print(\"   • No cost column found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Analysis\n",
        "print(\"=\"*60)\n",
        "print(\"DATA QUALITY ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"🔍 Missing Values Analysis:\")\n",
        "datasets = {\n",
        "    'Road Network': roads_df,\n",
        "    'Pavement Condition': condition_df,\n",
        "    'Maintenance Records': maintenance_df,\n",
        "    'Traffic Data': traffic_df\n",
        "}\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    missing = df.isnull().sum()\n",
        "    total = len(df)\n",
        "    print(f\"\\n{name}:\")\n",
        "    if missing.sum() == 0:\n",
        "        print(\"   ✅ No missing values\")\n",
        "    else:\n",
        "        for col, missing_count in missing[missing > 0].items():\n",
        "            pct = (missing_count / total) * 100\n",
        "            print(f\"   ⚠️ {col}: {missing_count:,} missing ({pct:.1f}%)\")\n",
        "\n",
        "# Check for duplicates\n",
        "print(f\"\\n🔍 Duplicate Records Analysis:\")\n",
        "for name, df in datasets.items():\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"   • {name}: {duplicates:,} duplicate records\")\n",
        "\n",
        "# Check data types\n",
        "print(f\"\\n🔍 Data Types Analysis:\")\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        print(f\"   • {col}: {dtype}\")\n",
        "\n",
        "# Check for outliers in condition scores (if column exists)\n",
        "print(f\"\\n🔍 Outlier Analysis (Condition Scores):\")\n",
        "condition_score_col = None\n",
        "for col in condition_df.columns:\n",
        "    if col.upper() == 'CONDITION_SCORE':\n",
        "        condition_score_col = col\n",
        "        break\n",
        "\n",
        "if condition_score_col:\n",
        "    Q1 = condition_df[condition_score_col].quantile(0.25)\n",
        "    Q3 = condition_df[condition_score_col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = condition_df[(condition_df[condition_score_col] < lower_bound) | \n",
        "                           (condition_df[condition_score_col] > upper_bound)]\n",
        "    print(f\"   • Outliers detected: {len(outliers):,} ({len(outliers)/len(condition_df)*100:.1f}%)\")\n",
        "    print(f\"   • Normal range: {lower_bound:.1f} to {upper_bound:.1f}\")\n",
        "else:\n",
        "    print(\"   • No condition_score column found - cannot perform outlier analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 1: Condition Score Distribution\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Get column names (handle case sensitivity)\n",
        "condition_score_col = None\n",
        "segment_id_col = None\n",
        "road_type_col = None\n",
        "date_col = None\n",
        "\n",
        "for col in condition_df.columns:\n",
        "    if col.upper() == 'CONDITION_SCORE':\n",
        "        condition_score_col = col\n",
        "    elif col.upper() == 'SEGMENT_ID':\n",
        "        segment_id_col = col\n",
        "\n",
        "for col in roads_df.columns:\n",
        "    if col.upper() == 'ROAD_TYPE':\n",
        "        road_type_col = col\n",
        "    elif col.upper() == 'SEGMENT_ID':\n",
        "        segment_id_col = col\n",
        "\n",
        "for col in condition_df.columns:\n",
        "    if col.upper() == 'DATE':\n",
        "        date_col = col\n",
        "\n",
        "# Histogram of condition scores\n",
        "plt.subplot(1, 3, 1)\n",
        "if condition_score_col:\n",
        "    plt.hist(condition_df[condition_score_col], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    plt.title('Distribution of Pavement Condition Scores')\n",
        "    plt.xlabel('Condition Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No condition_score column found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Condition Score Distribution - Data Not Available')\n",
        "\n",
        "# Box plot by road type\n",
        "plt.subplot(1, 3, 2)\n",
        "if condition_score_col and segment_id_col and road_type_col:\n",
        "    try:\n",
        "        condition_with_road_type = condition_df.merge(roads_df[[segment_id_col, road_type_col]], on=segment_id_col)\n",
        "        print(f\"Columns after merge: {list(condition_with_road_type.columns)}\")\n",
        "        \n",
        "        # Find the actual road type column name after merge\n",
        "        merged_road_type_col = None\n",
        "        for col in condition_with_road_type.columns:\n",
        "            if col.upper() == 'ROAD_TYPE':\n",
        "                merged_road_type_col = col\n",
        "                break\n",
        "        \n",
        "        if merged_road_type_col:\n",
        "            road_types = condition_with_road_type[merged_road_type_col].unique()\n",
        "            box_data = [condition_with_road_type[condition_with_road_type[merged_road_type_col] == rt][condition_score_col].values \n",
        "                       for rt in road_types]\n",
        "            plt.boxplot(box_data, labels=road_types)\n",
        "            plt.title('Condition Scores by Road Type')\n",
        "            plt.xlabel('Road Type')\n",
        "            plt.ylabel('Condition Score')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Road type column not found after merge', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "            plt.title('Condition by Road Type - Column Not Found')\n",
        "    except Exception as e:\n",
        "        plt.text(0.5, 0.5, f'Error in merge: {str(e)[:50]}...', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Condition by Road Type - Merge Error')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Condition by Road Type - Data Not Available')\n",
        "\n",
        "# Time series of average condition\n",
        "plt.subplot(1, 3, 3)\n",
        "if date_col and condition_score_col:\n",
        "    monthly_condition = condition_df.groupby(condition_df[date_col].dt.to_period('M'))[condition_score_col].mean()\n",
        "    plt.plot(monthly_condition.index.astype(str), monthly_condition.values, marker='o', linewidth=2)\n",
        "    plt.title('Average Condition Score Over Time')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Average Condition Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Date or condition_score column not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Condition Over Time - Data Not Available')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Visualization 1 Complete: Condition Score Analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 2: Maintenance Cost Analysis\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Get column names (handle case sensitivity)\n",
        "cost_col = None\n",
        "repair_type_col = None\n",
        "date_col = None\n",
        "\n",
        "for col in maintenance_df.columns:\n",
        "    if col.upper() == 'COST':\n",
        "        cost_col = col\n",
        "    elif col.upper() == 'REPAIR_TYPE':\n",
        "        repair_type_col = col\n",
        "    elif col.upper() == 'DATE':\n",
        "        date_col = col\n",
        "\n",
        "# Maintenance cost distribution\n",
        "plt.subplot(1, 3, 1)\n",
        "if cost_col:\n",
        "    plt.hist(maintenance_df[cost_col], bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "    plt.title('Distribution of Maintenance Costs')\n",
        "    plt.xlabel('Cost ($)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No cost column found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Cost Distribution - Data Not Available')\n",
        "\n",
        "# Cost by repair type\n",
        "plt.subplot(1, 3, 2)\n",
        "if cost_col and repair_type_col:\n",
        "    cost_by_type = maintenance_df.groupby(repair_type_col)[cost_col].mean().sort_values(ascending=False)\n",
        "    cost_by_type.plot(kind='bar', color='lightgreen')\n",
        "    plt.title('Average Cost by Repair Type')\n",
        "    plt.xlabel('Repair Type')\n",
        "    plt.ylabel('Average Cost ($)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Cost by Repair Type - Data Not Available')\n",
        "\n",
        "# Monthly maintenance spending\n",
        "plt.subplot(1, 3, 3)\n",
        "if date_col and cost_col:\n",
        "    monthly_costs = maintenance_df.groupby(maintenance_df[date_col].dt.to_period('M'))[cost_col].sum()\n",
        "    plt.plot(monthly_costs.index.astype(str), monthly_costs.values, marker='s', linewidth=2, color='orange')\n",
        "    plt.title('Monthly Maintenance Spending')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Total Cost ($)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Date or cost column not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Monthly Spending - Data Not Available')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Visualization 2 Complete: Maintenance Cost Analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 3: Traffic and Condition Correlation\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Get additional column names\n",
        "traffic_volume_col = None\n",
        "roughness_col = None\n",
        "cracking_col = None\n",
        "pothole_col = None\n",
        "\n",
        "for col in roads_df.columns:\n",
        "    if col.upper() == 'TRAFFIC_VOLUME':\n",
        "        traffic_volume_col = col\n",
        "\n",
        "for col in condition_df.columns:\n",
        "    if col.upper() == 'ROUGHNESS_INDEX':\n",
        "        roughness_col = col\n",
        "    elif col.upper() == 'CRACKING_PERCENT':\n",
        "        cracking_col = col\n",
        "    elif col.upper() == 'POTHOLE_COUNT':\n",
        "        pothole_col = col\n",
        "\n",
        "# Traffic volume vs condition score\n",
        "plt.subplot(1, 3, 1)\n",
        "if condition_score_col and segment_id_col and traffic_volume_col:\n",
        "    try:\n",
        "        condition_with_traffic = condition_df.merge(roads_df[[segment_id_col, traffic_volume_col]], on=segment_id_col)\n",
        "        plt.scatter(condition_with_traffic[traffic_volume_col], condition_with_traffic[condition_score_col], \n",
        "                   alpha=0.5, s=10, color='purple')\n",
        "        plt.title('Traffic Volume vs Condition Score')\n",
        "        plt.xlabel('Traffic Volume (vehicles/day)')\n",
        "        plt.ylabel('Condition Score')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "    except Exception as e:\n",
        "        plt.text(0.5, 0.5, f'Error: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Traffic vs Condition - Error')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Traffic vs Condition - Data Not Available')\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.subplot(1, 3, 2)\n",
        "if condition_score_col and traffic_volume_col and roughness_col and cracking_col and pothole_col:\n",
        "    try:\n",
        "        correlation_cols = [condition_score_col, traffic_volume_col, roughness_col, cracking_col, pothole_col]\n",
        "        correlation_data = condition_with_traffic[correlation_cols].corr()\n",
        "        sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, square=True)\n",
        "        plt.title('Feature Correlation Matrix')\n",
        "    except Exception as e:\n",
        "        plt.text(0.5, 0.5, f'Error: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Correlation Matrix - Error')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Correlation Matrix - Data Not Available')\n",
        "\n",
        "# Condition degradation over time by road type\n",
        "plt.subplot(1, 3, 3)\n",
        "if date_col and condition_score_col and segment_id_col and road_type_col:\n",
        "    try:\n",
        "        condition_with_road_type = condition_df.merge(roads_df[[segment_id_col, road_type_col]], on=segment_id_col)\n",
        "        merged_road_type_col = None\n",
        "        for col in condition_with_road_type.columns:\n",
        "            if col.upper() == 'ROAD_TYPE':\n",
        "                merged_road_type_col = col\n",
        "                break\n",
        "        \n",
        "        if merged_road_type_col:\n",
        "            for road_type in condition_with_road_type[merged_road_type_col].unique():\n",
        "                road_data = condition_with_road_type[condition_with_road_type[merged_road_type_col] == road_type]\n",
        "                monthly_condition = road_data.groupby(road_data[date_col].dt.to_period('M'))[condition_score_col].mean()\n",
        "                plt.plot(monthly_condition.index.astype(str), monthly_condition.values, \n",
        "                         marker='o', label=road_type, linewidth=2)\n",
        "            plt.title('Condition Trends by Road Type')\n",
        "            plt.xlabel('Month')\n",
        "            plt.ylabel('Average Condition Score')\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, 'Road type column not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "            plt.title('Condition Trends - Column Not Found')\n",
        "    except Exception as e:\n",
        "        plt.text(0.5, 0.5, f'Error: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.title('Condition Trends - Error')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Condition Trends - Data Not Available')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Visualization 3 Complete: Traffic and Condition Analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary and Key Insights\n",
        "print(\"=\"*60)\n",
        "print(\"KEY INSIGHTS FROM DATA EXPLORATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get column names for calculations\n",
        "segment_length_col = None\n",
        "cost_col = None\n",
        "condition_score_col = None\n",
        "segment_id_col = None\n",
        "road_type_col = None\n",
        "repair_type_col = None\n",
        "\n",
        "for col in roads_df.columns:\n",
        "    if col.upper() == 'SEGMENT_LENGTH_MILES':\n",
        "        segment_length_col = col\n",
        "    elif col.upper() == 'ROAD_TYPE':\n",
        "        road_type_col = col\n",
        "\n",
        "for col in maintenance_df.columns:\n",
        "    if col.upper() == 'COST':\n",
        "        cost_col = col\n",
        "    elif col.upper() == 'REPAIR_TYPE':\n",
        "        repair_type_col = col\n",
        "\n",
        "for col in condition_df.columns:\n",
        "    if col.upper() == 'CONDITION_SCORE':\n",
        "        condition_score_col = col\n",
        "    elif col.upper() == 'SEGMENT_ID':\n",
        "        segment_id_col = col\n",
        "\n",
        "# Calculate key metrics\n",
        "total_road_miles = roads_df[segment_length_col].sum() if segment_length_col else 0\n",
        "total_maintenance_cost = maintenance_df[cost_col].sum() if cost_col else 0\n",
        "avg_condition = condition_df[condition_score_col].mean() if condition_score_col else 0\n",
        "worst_condition = condition_df[condition_score_col].min() if condition_score_col else 0\n",
        "best_condition = condition_df[condition_score_col].max() if condition_score_col else 0\n",
        "\n",
        "print(f\"📊 Infrastructure Overview:\")\n",
        "print(f\"   • Total road network: {total_road_miles:,.0f} miles\")\n",
        "print(f\"   • Total maintenance investment: ${total_maintenance_cost:,.0f}\")\n",
        "print(f\"   • Average condition score: {avg_condition:.1f}/100\")\n",
        "print(f\"   • Condition range: {worst_condition:.1f} to {best_condition:.1f}\")\n",
        "\n",
        "# Identify problem areas\n",
        "if condition_score_col:\n",
        "    poor_condition = condition_df[condition_df[condition_score_col] < 30]\n",
        "    print(f\"\\n⚠️ Problem Areas Identified:\")\n",
        "    print(f\"   • Segments in poor condition (<30): {len(poor_condition):,}\")\n",
        "    print(f\"   • Percentage needing attention: {len(poor_condition)/len(condition_df)*100:.1f}%\")\n",
        "    \n",
        "    # Try to get high-traffic poor condition if we can merge the data\n",
        "    try:\n",
        "        if segment_id_col and 'TRAFFIC_VOLUME' in [col.upper() for col in roads_df.columns]:\n",
        "            traffic_volume_col = None\n",
        "            for col in roads_df.columns:\n",
        "                if col.upper() == 'TRAFFIC_VOLUME':\n",
        "                    traffic_volume_col = col\n",
        "                    break\n",
        "            \n",
        "            if traffic_volume_col:\n",
        "                condition_with_traffic = condition_df.merge(roads_df[[segment_id_col, traffic_volume_col]], on=segment_id_col)\n",
        "                high_traffic_poor_condition = condition_with_traffic[\n",
        "                    (condition_with_traffic[condition_score_col] < 30) & \n",
        "                    (condition_with_traffic[traffic_volume_col] > 25000)\n",
        "                ]\n",
        "                print(f\"   • High-traffic poor condition: {len(high_traffic_poor_condition):,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   • High-traffic analysis: Could not complete ({str(e)[:50]}...)\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ Problem Areas: Cannot analyze - condition_score column not found\")\n",
        "\n",
        "# Cost analysis\n",
        "if cost_col and segment_length_col and total_road_miles > 0:\n",
        "    cost_per_mile = total_maintenance_cost / total_road_miles\n",
        "    print(f\"\\n💰 Cost Analysis:\")\n",
        "    print(f\"   • Average cost per mile: ${cost_per_mile:,.0f}\")\n",
        "    \n",
        "    if repair_type_col:\n",
        "        most_expensive = maintenance_df.groupby(repair_type_col)[cost_col].mean().idxmax()\n",
        "        print(f\"   • Most expensive repair type: {most_expensive}\")\n",
        "    \n",
        "    print(f\"   • Average repair cost: ${maintenance_df[cost_col].mean():,.0f}\")\n",
        "else:\n",
        "    print(f\"\\n💰 Cost Analysis: Cannot complete - required columns not found\")\n",
        "\n",
        "# Recommendations\n",
        "print(f\"\\n🎯 Initial Recommendations:\")\n",
        "if condition_score_col and segment_id_col:\n",
        "    poor_condition_count = len(condition_df[condition_df[condition_score_col] < 30])\n",
        "    unique_segments = condition_df[condition_df[condition_score_col] < 30][segment_id_col].nunique()\n",
        "    print(f\"   • Focus on {poor_condition_count:,} segments in poor condition\")\n",
        "    print(f\"   • Prioritize {unique_segments:,} unique segments needing repair\")\n",
        "    print(f\"   • Consider preventive maintenance for segments scoring 30-50\")\n",
        "else:\n",
        "    print(f\"   • Cannot provide specific recommendations - data columns not found\")\n",
        "\n",
        "if road_type_col:\n",
        "    most_common_road_type = roads_df[road_type_col].value_counts().idxmax()\n",
        "    print(f\"   • Monitor {most_common_road_type} roads (most common type)\")\n",
        "\n",
        "print(f\"\\n✅ Data exploration complete! Ready for feature engineering.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional Analysis (if needed)\n",
        "print(\"=\"*60)\n",
        "print(\"ADDITIONAL ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if we have all the data we need for comprehensive analysis\n",
        "print(\"Data availability check:\")\n",
        "print(f\"✅ Road network: {len(roads_df):,} segments\")\n",
        "print(f\"✅ Pavement condition: {len(condition_df):,} records\")\n",
        "print(f\"✅ Maintenance records: {len(maintenance_df):,} records\")\n",
        "print(f\"✅ Traffic data: {len(traffic_df):,} records\")\n",
        "\n",
        "# Check column availability\n",
        "print(f\"\\nColumn availability:\")\n",
        "print(f\"Road network columns: {list(roads_df.columns)}\")\n",
        "print(f\"Pavement condition columns: {list(condition_df.columns)}\")\n",
        "print(f\"Maintenance records columns: {list(maintenance_df.columns)}\")\n",
        "print(f\"Traffic data columns: {list(traffic_df.columns)}\")\n",
        "\n",
        "print(f\"\\n🎉 Data exploration notebook completed successfully!\")\n",
        "print(f\"Ready to proceed to feature engineering and ML modeling.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
